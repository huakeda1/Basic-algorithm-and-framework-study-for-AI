{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from transformers import BertConfig,BertTokenizer,BertModel,AdamW\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "    def __init__(self,data_path,vocab_path,max_length=384):\n",
    "        super(SquadDataset,self).__init__()\n",
    "        self.data_path=data_path\n",
    "        self.data_samples=self.get_samples(data_path)\n",
    "        self.tokenizer=BertTokenizer.from_pretrained(vocab_path)\n",
    "        self.max_length=max_length\n",
    "    def get_examples_from_data(self,data):\n",
    "        examples=[]\n",
    "        title=data['title']\n",
    "        for paragraph in data['paragraphs']:\n",
    "            context=paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                qid=qa['id']\n",
    "                question=qa['question']\n",
    "                if \"is_impossible\" in qa:\n",
    "                    is_impossible=qa['is_impossible']\n",
    "                else:\n",
    "                    is_impossible=len(qa['answers'])==0\n",
    "                if is_impossible:\n",
    "                    current_example={'qas_id':qid,'question_text':question,'context_text':context,'is_impossible':is_impossible,'answer_text':''}\n",
    "                    examples.append(current_example)\n",
    "                else:\n",
    "                    current_answer_collectors=[]\n",
    "                    for answer in qa['answers']:\n",
    "                        text=answer['text']\n",
    "                        if text in current_answer_collectors:\n",
    "                            continue\n",
    "                        else:\n",
    "                            current_answer_collectors.append(text)\n",
    "                        answer=answer['answer_start']\n",
    "                        current_example={'qas_id':qid,'question_text':question,'context_text':context,'is_impossible':is_impossible,'answer_text':text}\n",
    "                        examples.append(current_example)\n",
    "        return examples\n",
    "    def get_samples(self,data_path):\n",
    "        with open(data_path,'r',encoding='utf-8') as f:\n",
    "            dataset=json.load(f)\n",
    "            all_data=dataset['data']\n",
    "        processor=multiprocessing.cpu_count()\n",
    "        p=Pool(processor)\n",
    "        result_list=p.map(self.get_examples_from_data,all_data)\n",
    "        all_examples=[]\n",
    "        for examples in result_list:\n",
    "            all_examples+=examples\n",
    "        p.close()\n",
    "        return all_examples\n",
    "    def get_answer_start(self,answer_ids,sequence_ids):\n",
    "        for i in range(len(sequence_ids)):\n",
    "            if sequence_ids[i:i+len(answer_ids)]==answer_ids:\n",
    "                return i\n",
    "        return -1\n",
    "    def __getitem__(self,i):\n",
    "        \n",
    "        qid=self.data_samples[i]['qas_id']\n",
    "        question=self.data_samples[i]['question_text']\n",
    "        context=self.data_samples[i]['context_text']\n",
    "        output=self.tokenizer.encode_plus(question,context,add_special_tokens=True,max_length=self.max_length,padding='max_length',truncation=True)\n",
    "        answer=self.data_samples[i]['answer_text']\n",
    "        output.update({'answer_text':answer if answer!=None else '','qas_id':qid})\n",
    "        if answer=='' or answer==None:\n",
    "            label=(0,0)\n",
    "        else:\n",
    "            pure_answer_ids=self.tokenizer.encode(answer)[1:-1]\n",
    "            start=self.get_answer_start(pure_answer_ids,output['input_ids'])\n",
    "            if start!=-1:\n",
    "                label=(start,start+len(pure_answer_ids)-1)\n",
    "            else:\n",
    "                label=(0,0)\n",
    "        return output,label\n",
    "    def __len__(self):\n",
    "        return len(self.data_samples)\n",
    "def collate_func(batch):\n",
    "    def padding(indices,max_length,pad_idx=0):\n",
    "        pad_indices=[item+[pad_idx]*max(0,max_length-len(item)) for item in indices]\n",
    "        return torch.tensor(pad_indices)\n",
    "    # if padding = 'max_length' is not used in tokenizer.encode_plust fuction, then you should pad the sequences to the same size.\n",
    "    \n",
    "#     result=[(output['input_ids'],output['token_type_ids'],output['attention_mask'],label) for output,label in batch]\n",
    "#     input_ids,token_type_ids,attention_mask,labels=zip(*result)\n",
    "#     labels=torch.tensor(labels)\n",
    "#     max_length=max([len(t) for t in input_ids])\n",
    "    \n",
    "#     input_ids_padded=padding(input_ids,max_length)\n",
    "#     token_type_ids_padded=padding(token_type_ids,max_length)\n",
    "#     attention_mask_padded=padding(attention_mask,max_length)\n",
    "#     return input_ids_padded,token_type_ids_padded,attention_mask_padded,labels\n",
    "\n",
    "    # if padding = 'max_length' is used in tokenizer.encode_plust fuction, then there is no need to pad the sequences to the same size.\n",
    "    result=[(output['input_ids'],output['token_type_ids'],output['attention_mask'],label) for output,label in batch]\n",
    "    input_ids,token_type_ids,attention_mask,labels=zip(*result)\n",
    "    return torch.tensor(input_ids),torch.tensor(token_type_ids),torch.tensor(attention_mask),torch.tensor(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSquad(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(BertForSquad,self).__init__()\n",
    "        # To determine whether the token is the starting point or end point of the answer, that is actually a two category question.\n",
    "        self.num_labels=config.num_labels\n",
    "        self.config=config\n",
    "        model_config=BertConfig.from_pretrained(config.bert_path)\n",
    "        self.bert=BertModel.from_pretrained(config.bert_path,config=model_config)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad=True\n",
    "        self.gru = []\n",
    "        for i in range(config.gru_layers):\n",
    "            self.gru.append(\n",
    "                nn.GRU(\n",
    "                    config.hidden_size if i == 0 else config.gru_hidden_size * 2,\n",
    "                    config.gru_hidden_size,\n",
    "                    num_layers=1,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.gru = nn.ModuleList(self.gru)\n",
    "        self.qa_outputs = nn.Linear(config.gru_hidden_size * 2, config.num_labels)\n",
    "    def forward(self,x,initial_hidden_state):\n",
    "        input_ids,token_type_ids,attention_mask=x[0],x[1],x[2]\n",
    "        outputs=self.bert(input_ids,attention_mask,token_type_ids)\n",
    "        # get the output of every token\n",
    "        sequence_output=outputs[0]\n",
    "        for gru in self.gru:\n",
    "            try:\n",
    "                gru.flatten_parameters()\n",
    "            except:\n",
    "                pass\n",
    "            sequence_output, h_n = gru(sequence_output,initial_hidden_state)\n",
    "        logits=self.qa_outputs(sequence_output)\n",
    "        # get all start logits and end logits separately.\n",
    "        start_logits,end_logits=logits.split(1,dim=-1)\n",
    "        start_logits=start_logits.squeeze(-1)\n",
    "        end_logits=end_logits.squeeze(-1)\n",
    "        # end_logits shape (batch_size,sequence_len)\n",
    "        return start_logits,end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Config():\n",
    "    def __init__(self,):\n",
    "        self.bert_path=\"./pretrained_model/bert-base-uncased\"\n",
    "        self.train_data_path='./squad_v2/train-v2.0.json'\n",
    "        self.dev_data_path='./squad_v2/dev-v2.0.json'\n",
    "        self.num_labels=2\n",
    "        self.hidden_size=768\n",
    "        self.learning_rate=2.0e-5\n",
    "        self.bert_learning_rate=2e-5\n",
    "        self.other_learning_rate=5e-5\n",
    "        self.save_path='./save_model/customized_bert_for_squad.pt'\n",
    "        self.out_file='./output_evaluate/evaluate_prediction.json'\n",
    "        self.require_improvement=10000\n",
    "        self.device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        self.eps=1e-8\n",
    "        self.batch_size=32\n",
    "        self.num_epochs=1\n",
    "        self.dropout=0.3\n",
    "        self.max_sequence_len=256\n",
    "        self.max_a_len=20\n",
    "        self.gru_layers=1\n",
    "        self.gru_hidden_size=384\n",
    "# class Model_Config():\n",
    "#     def __init__(self,):\n",
    "#         self.bert_path='/home/aistudio/work/Squad-main/pretrained_model'\n",
    "#         self.train_data_path='/home/aistudio/work/Squad-main/data/squad/train-v2.0.json'\n",
    "#         self.dev_data_path='/home/aistudio/work/Squad-main/data/squad/dev-v2.0.json'\n",
    "#         self.num_labels=2\n",
    "#         self.hidden_size=768\n",
    "#         self.learning_rate=2.0e-5\n",
    "#         self.bert_learning_rate=2e-5\n",
    "#         self.other_learning_rate=2e-5\n",
    "#         self.save_path='/home/aistudio/work/Squad-main/save_model/customized_bert_for_squad.pt'\n",
    "#         self.out_file='/home/aistudio/work/Squad-main/output_evaluate/evaluate_prediction.json'\n",
    "#         self.require_improvement=10000\n",
    "#         self.device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#         self.eps=1e-8\n",
    "#         self.batch_size=32\n",
    "#         self.num_epochs=1\n",
    "#         self.dropout=0.3\n",
    "#         self.max_sequence_len=256\n",
    "#         self.max_a_len=20\n",
    "#         self.gru_layers=1\n",
    "#         self.gru_hidden_size=384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qid_to_has_ans(dataset):\n",
    "  qid_to_has_ans = {}\n",
    "  for article in dataset:\n",
    "    for p in article['paragraphs']:\n",
    "      for qa in p['qas']:\n",
    "        qid_to_has_ans[qa['id']] = bool(qa['answers'])\n",
    "  return qid_to_has_ans\n",
    "\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def get_tokens(s):\n",
    "  if not s: return []\n",
    "  return normalize_answer(s).split()\n",
    "\n",
    "def compute_exact(a_gold, a_pred):\n",
    "  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "  gold_toks = get_tokens(a_gold)\n",
    "  pred_toks = get_tokens(a_pred)\n",
    "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "  num_same = sum(common.values())\n",
    "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    return int(gold_toks == pred_toks)\n",
    "  if num_same == 0:\n",
    "    return 0\n",
    "  precision = 1.0 * num_same / len(pred_toks)\n",
    "  recall = 1.0 * num_same / len(gold_toks)\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "  return f1\n",
    "\n",
    "def get_raw_scores(dataset, preds):\n",
    "  exact_scores = {}\n",
    "  f1_scores = {}\n",
    "  for article in dataset:\n",
    "    for p in article['paragraphs']:\n",
    "      for qa in p['qas']:\n",
    "        qid = qa['id']\n",
    "        gold_answers = [a['text'] for a in qa['answers']\n",
    "                        if normalize_answer(a['text'])]\n",
    "        if not gold_answers:\n",
    "          # For unanswerable questions, only correct answer is empty string\n",
    "          gold_answers = ['']\n",
    "        if qid not in preds:\n",
    "          print('Missing prediction for %s' % qid)\n",
    "          continue\n",
    "        a_pred = preds[qid]\n",
    "        # Take max over all gold answers\n",
    "        exact_scores[qid] = max(compute_exact(a, a_pred) for a in gold_answers)\n",
    "        f1_scores[qid] = max(compute_f1(a, a_pred) for a in gold_answers)\n",
    "  return exact_scores, f1_scores\n",
    "\n",
    "def apply_no_ans_threshold(scores, na_probs, qid_to_has_ans, na_prob_thresh):\n",
    "  new_scores = {}\n",
    "  for qid, s in scores.items():\n",
    "    pred_na = na_probs[qid] > na_prob_thresh\n",
    "    if pred_na:\n",
    "      new_scores[qid] = float(not qid_to_has_ans[qid])\n",
    "    else:\n",
    "      new_scores[qid] = s\n",
    "  return new_scores\n",
    "\n",
    "def make_eval_dict(exact_scores, f1_scores, qid_list=None):\n",
    "  if not qid_list:\n",
    "    total = len(exact_scores)\n",
    "    return collections.OrderedDict([\n",
    "        ('exact', 100.0 * sum(exact_scores.values()) / total),\n",
    "        ('f1', 100.0 * sum(f1_scores.values()) / total),\n",
    "        ('total', total),\n",
    "    ])\n",
    "  else:\n",
    "    total = len(qid_list)\n",
    "    return collections.OrderedDict([\n",
    "        ('exact', 100.0 * sum(exact_scores[k] for k in qid_list) / total),\n",
    "        ('f1', 100.0 * sum(f1_scores[k] for k in qid_list) / total),\n",
    "        ('total', total),\n",
    "    ])\n",
    "\n",
    "def merge_eval(main_eval, new_eval, prefix):\n",
    "  for k in new_eval:\n",
    "    main_eval['%s_%s' % (prefix, k)] = new_eval[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_dataset(config,model,dev_dataset,is_test=False):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss=0.0\n",
    "    total_batches=0\n",
    "    \n",
    "    evaluate_output={}\n",
    "    \n",
    "    exact_scores={}\n",
    "    f1_scores={}\n",
    "    \n",
    "    qid_has_answer=set()\n",
    "    qid_no_answer=set()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index,(output,label) in tqdm(enumerate(dev_dataset)):\n",
    "            input_ids,token_type_ids,attention_mask=output['input_ids'],output['token_type_ids'],output['attention_mask']\n",
    "            prepared_input_ids=torch.tensor([input_ids]).to(config.device)\n",
    "            prepared_token_type_ids=torch.tensor([token_type_ids]).to(config.device)\n",
    "            prepared_attention_mask=torch.tensor([attention_mask]).to(config.device)\n",
    "            \n",
    "            qid=output['qas_id']\n",
    "            \n",
    "            labels=torch.tensor([label]).to(config.device)\n",
    "            \n",
    "            x=(prepared_input_ids,prepared_token_type_ids,prepared_attention_mask)\n",
    "            initial_hidden_state=torch.zeros(2,prepared_input_ids.shape[0],config.gru_hidden_size).to(config.device)\n",
    "            start_logits,end_logits=model(x,initial_hidden_state)\n",
    "            \n",
    "            start_loss=torch.nn.functional.cross_entropy(start_logits,labels[:,0])\n",
    "            end_loss=torch.nn.functional.cross_entropy(end_logits,labels[:,1])\n",
    "            combined_loss=(start_loss+end_loss)/2\n",
    "            total_loss+=combined_loss.item()\n",
    "            total_batches+=1\n",
    "            \n",
    "            start_probas,end_probas=torch.softmax(start_logits,dim=-1)[0],torch.softmax(end_logits,dim=-1)[0]\n",
    "            \n",
    "            start_end, score = None, -1\n",
    "            for start, p_start in enumerate(start_probas):\n",
    "                for end, p_end in enumerate(end_probas):\n",
    "                    if end >= start and end < start + config.max_a_len:\n",
    "                        if p_start * p_end > score:\n",
    "                            start_end = (start, end)\n",
    "                            score = p_start * p_end\n",
    "            start, end = start_end\n",
    "            pred_answer=dev_dataset.tokenizer.convert_tokens_to_string(dev_dataset.tokenizer.convert_ids_to_tokens(input_ids[start:end+1],skip_special_tokens=True))\n",
    "            \n",
    "            evaluate_output[qid]=pred_answer\n",
    "            if not is_test:\n",
    "                answer=output['answer_text']\n",
    "                if answer=='' or answer==None:\n",
    "                    qid_no_answer.add(qid)\n",
    "                else:\n",
    "                    qid_has_answer.add(qid)\n",
    "\n",
    "                if qid in exact_scores:\n",
    "                    exact_scores[qid]=max(exact_scores[qid],compute_exact(answer, pred_answer))\n",
    "                else:\n",
    "                    exact_scores[qid]=compute_exact(answer, pred_answer)\n",
    "                if qid in f1_scores:\n",
    "                    f1_scores[qid] = max(f1_scores[qid],compute_f1(answer, pred_answer))\n",
    "                else:\n",
    "                    f1_scores[qid] = compute_f1(answer, pred_answer)\n",
    "    if not is_test:\n",
    "        total_result=make_eval_dict(exact_scores, f1_scores, qid_list=None)\n",
    "        has_answer_result=make_eval_dict(exact_scores, f1_scores, qid_list=qid_has_answer)\n",
    "        no_answer_result=make_eval_dict(exact_scores, f1_scores, qid_list=qid_no_answer)\n",
    "        merge_eval(total_result,has_answer_result,prefix='HasAns')\n",
    "        merge_eval(total_result,no_answer_result,prefix='NoAns')\n",
    "        print('evaluation_performace:',total_result)\n",
    "    else:\n",
    "        total_result={}\n",
    "    fw = open(config.out_file, 'w', encoding='utf-8')\n",
    "    R = json.dumps(evaluate_output, ensure_ascii=False, indent=4)\n",
    "    fw.write(R)\n",
    "    fw.close()\n",
    "    return total_loss/total_batches,total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_during_training(config,model,dev_iter):\n",
    "    model.eval()\n",
    "    total_loss=0.0\n",
    "    total_batches=0\n",
    "    with torch.no_grad():\n",
    "        for index,(input_ids,token_type_ids,attention_mask,labels) in tqdm(enumerate(dev_iter)):\n",
    "            input_ids=input_ids.to(config.device)\n",
    "            token_type_ids=token_type_ids.to(config.device)\n",
    "            attention_mask=attention_mask.to(config.device)\n",
    "            labels=labels.to(config.device)\n",
    "            x=(input_ids,token_type_ids,attention_mask)\n",
    "            initial_hidden_state=torch.zeros(2,input_ids.shape[0],config.gru_hidden_size).to(config.device)\n",
    "            start_logits,end_logits=model(x,initial_hidden_state)\n",
    "            start_loss=torch.nn.functional.cross_entropy(start_logits,labels[:,0])\n",
    "            end_loss=torch.nn.functional.cross_entropy(end_logits,labels[:,1])\n",
    "            combined_loss=(start_loss+end_loss)/2\n",
    "            total_loss+=combined_loss.item()\n",
    "            total_batches+=1\n",
    "    return total_loss/total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config,model,train_iter,dev_iter):\n",
    "    model.train()\n",
    "    print(config.device)\n",
    "    bert_param_optimizer=list(model.bert.named_parameters())\n",
    "    bert_params=list(map(id,model.bert.parameters()))\n",
    "    other_param_optimizer=[(n,p) for n,p in model.named_parameters() if id(p) not in bert_params]\n",
    "    no_decay=['bias','LayerNorm.bias','LayerNorm.weight']\n",
    "    optimizer_grouped_parameters=[\n",
    "        {'params':[p for n,p in bert_param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay':0.01,'lr':config.bert_learning_rate},\n",
    "        {'params':[p for n,p in bert_param_optimizer if any(nd in n for nd in no_decay)],'weight_decay':0,'lr':config.bert_learning_rate},\n",
    "        {'params':[p for n,p in other_param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay':0.01,'lr':config.other_learning_rate},\n",
    "        {'params':[p for n,p in other_param_optimizer if any(nd in n for nd in no_decay)],'weight_decay':0,'lr':config.other_learning_rate}]\n",
    "    optimizer=AdamW(optimizer_grouped_parameters,lr=config.learning_rate,eps=config.eps)\n",
    "    total_batch=0\n",
    "    best_dev_loss=float('inf')\n",
    "    last_improve=0\n",
    "    flag=False # record whether the model is not learning any more\n",
    "    for epoch in range(config.num_epochs):\n",
    "        epoch_start_time=time.time()\n",
    "        print('Epoch:{}/{}'.format(epoch+1,config.num_epochs))\n",
    "        batched_loss=0\n",
    "        for index,(input_ids,token_type_ids,attention_mask,labels) in tqdm(enumerate(train_iter)):\n",
    "            batch_start_time=time.time()\n",
    "            input_ids=input_ids.to(config.device)\n",
    "            token_type_ids=token_type_ids.to(config.device)\n",
    "            attention_mask=attention_mask.to(config.device)\n",
    "            labels=labels.to(config.device)\n",
    "            x=(input_ids,token_type_ids,attention_mask)\n",
    "            initial_hidden_state=torch.zeros(2,input_ids.shape[0],config.gru_hidden_size).to(config.device)\n",
    "            start_logits,end_logits=model(x,initial_hidden_state)\n",
    "            model.zero_grad()\n",
    "            start_loss=torch.nn.functional.cross_entropy(start_logits,labels[:,0])\n",
    "            end_loss=torch.nn.functional.cross_entropy(end_logits,labels[:,1])\n",
    "            total_loss=(start_loss+end_loss)/2\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            batched_loss+=total_loss.item()\n",
    "            if total_batch%3000==0 and total_batch!=0:\n",
    "                avg_dev_loss=evaluate_during_training(config,model,dev_iter)\n",
    "                if avg_dev_loss<best_dev_loss:\n",
    "                    best_dev_loss=avg_dev_loss\n",
    "                    torch.save(model.state_dict(),config.save_path)\n",
    "                    last_improve=total_batch\n",
    "                print('Epoch:{},Batch:{},Avg_train_loss:{},Avg_dev_loss:{}'.format(epoch+1,index+1,batched_loss/(index+1),avg_dev_loss))\n",
    "                model.train()\n",
    "            total_batch+=1\n",
    "            print('Epoch:{},Batch:{},Avg_train_loss:{}'.format(epoch+1,index+1,batched_loss/(index+1)))\n",
    "            print('Time cost for one batch:',time.time()-batch_start_time)\n",
    "            if total_batch-last_improve>config.require_improvement:\n",
    "                print(\"No optimization for a long time, auto_stopping...\")\n",
    "                flag=True\n",
    "                break\n",
    "        print('Time cost for one epoch:',time.time()-epoch_start_time)\n",
    "        if flag:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config=Model_Config()\n",
    "start_time=time.time()\n",
    "train_dataset=SquadDataset(data_path=model_config.train_data_path,vocab_path=model_config.bert_path,max_length=model_config.max_sequence_len)\n",
    "dev_dataset=SquadDataset(data_path=model_config.dev_data_path,vocab_path=model_config.bert_path,max_length=model_config.max_sequence_len)\n",
    "print('building_time:',time.time()-start_time)\n",
    "\n",
    "processor=multiprocessing.cpu_count()\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=model_config.batch_size,collate_fn=collate_func,num_workers=processor)\n",
    "dev_dataloader=DataLoader(dev_dataset,batch_size=model_config.batch_size,collate_fn=collate_func,num_workers=processor)\n",
    "\n",
    "model=BertForSquad(model_config)\n",
    "if os.path.exists(model_config.save_path):\n",
    "    model.load_state_dict(torch.load(model_config.save_path,map_location=model_config.device))\n",
    "model.to(model_config.device)\n",
    "train(model_config,model,train_dataloader,dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config=Model_Config()\n",
    "dev_dataset=SquadDataset(data_path=model_config.dev_data_path,vocab_path=model_config.bert_path,max_length=model_config.max_sequence_len)\n",
    "model=BertForSquad(model_config)\n",
    "if os.path.exists(model_config.save_path):\n",
    "    model.load_state_dict(torch.load(model_config.save_path,map_location=model_config.device))\n",
    "model.to(model_config.device)\n",
    "dev_avg_loss,dev_pred_performance=predict_for_dataset(model_config,model,dev_dataset)\n",
    "print(dev_avg_loss)\n",
    "print(dev_pred_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_single_example(model,tokenizer,question,context,config,verbose=False):\n",
    "    model.eval()\n",
    "    inputs=tokenizer.encode_plus(question, context, max_length=config.max_sequence_len, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    token_ids=inputs['input_ids'].tolist()[0]\n",
    "    \n",
    "    input_ids=inputs['input_ids'].to(config.device)\n",
    "    token_type_ids=inputs['token_type_ids'].to(config.device)\n",
    "    attention_mask=inputs['attention_mask'].to(config.device)\n",
    "    \n",
    "    x=(input_ids,token_type_ids,attention_mask)\n",
    "    initial_hidden_state=torch.zeros(2,input_ids.shape[0],config.gru_hidden_size).to(config.device)\n",
    "    start_logits,end_logits=model(x,initial_hidden_state)\n",
    "    \n",
    "    start_probas,end_probas=torch.softmax(start_logits,dim=-1)[0],torch.softmax(end_logits,dim=-1)[0]\n",
    "            \n",
    "    start_end, score = None, -1\n",
    "    for start, p_start in enumerate(start_probas):\n",
    "        for end, p_end in enumerate(end_probas):\n",
    "            if end >= start and end < start + config.max_a_len:\n",
    "                if p_start * p_end > score:\n",
    "                    start_end = (start, end)\n",
    "                    score = p_start * p_end\n",
    "    start, end = start_end\n",
    "    pred_answer=tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(token_ids[start:end+1],skip_special_tokens=True))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Question:{question}')\n",
    "        print(f'Context:{context}')\n",
    "        if pred_answer=='':\n",
    "            print('There is no answer in the context for this question')\n",
    "        else:\n",
    "            print(f'Answer:{pred_answer}')\n",
    "    return pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSquad(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (gru): ModuleList(\n",
       "    (0): GRU(768, 384, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config=Model_Config()\n",
    "tokenizer=BertTokenizer.from_pretrained(model_config.bert_path)\n",
    "model=BertForSquad(model_config)\n",
    "if os.path.exists(model_config.save_path):\n",
    "    model.load_state_dict(torch.load(model_config.save_path,map_location=torch.device('cpu')))\n",
    "model.to(model_config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original context\n",
    "To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
    "\n",
    "# original question and answer\n",
    "1、why does person wear clothes? \n",
    "for protection and for decoration. \n",
    "2、where does wool come from? \n",
    "It comes from sheep,as well as some other animals.\n",
    "3、why In warm countries people like to wear cotton clothes? \n",
    "because they are soft, cool and comfortable . \n",
    "4、why synthetic materials are cheaper than natural fabrics?\n",
    "because they are more comfortable than synthetics \n",
    "5、which is cheaper between cotton clothes and wool garments? \n",
    "Cotton clothes\n",
    "6、how are clothes made of wool ?\n",
    "They are very light and warm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:12<01:01, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:why does person wear clothes?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "Answer:for protection and for decoration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:24<00:49, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:where does wool come from?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "Answer:sheep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:32<00:32, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:why In warm countries people like to wear cotton clothes?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "Answer:they are soft , cool and comfortable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:32<00:15,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:why synthetic materials are cheaper than natural fabrics?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "Answer:they are more comfortable than synthetics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:43<00:08,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:which is cheaper between cotton clothes and wool garments?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "There is no answer in the context for this question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:56<00:00,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:how are clothes made of wool?\n",
      "Context:To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\n",
      "Answer:very light and warm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questiones=[\"why does person wear clothes?\",\"where does wool come from?\",\"why In warm countries people like to wear cotton clothes?\",\"why synthetic materials are cheaper than natural fabrics?\",\"which is cheaper between cotton clothes and wool garments?\",\"how are clothes made of wool?\"]\n",
    "context=\"To eat is one human need ,and to wear clothes is another human need.People wear clothes for protection and for decoration.There are many kinds of materials for making clothes .Wool is one kind .It comes from sheep,as well as some other animals. Clothes made of wool are very light and warm.In warm countries people like to wear cotton clothes ,because they are soft, cool and comfortable .Cotton clothes are also cheaper than wool garments.Two other materials are silk and linen .Now synthetic materials are also common ,and they are cheaper than natural fabrics, because they are more comfortable than synthetics.\"\n",
    "for index,question in enumerate(tqdm(questiones)):\n",
    "    pred_answer=predict_for_single_example(model,tokenizer,question,context,model_config,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# customized_bert_model_for_squad\n",
    "We build a customized bert model for squad examples, here you can understand how to build a **model** on base of bert, how to build a **dataset** or **dataloader** for squad similar type of examples，how to build the **train, evaluate and predict** function for squad similar type of examples, some of the code is borrowed from **run_squad.py** scripts, you can build a complete model for question answering type of projects with the template code here. \n",
    "\n",
    "## Packages\n",
    "- Transformers 3.5.0\n",
    "- Torch\n",
    "\n",
    "## The process is the following:\n",
    "- 1) Build a dataset and dataloader inherited from torch.utils.data.Dataset/Dataloader to process squad data\n",
    "\n",
    "- 2) Build a powerful model by adding GRU layers and classification layers on top of bert.\n",
    "\n",
    "- 3) Build two predict functions, one is for single example prediction, the other is for dataset prediction or evaluation.\n",
    "\n",
    "- 4) Build an evaluate function which can be used during training to evaluate the performance of the model.\n",
    "\n",
    "- 5) Build a powerful train function to train the model, the specific evaluation index will be shown out, the model will be saved in predefined condition.\n",
    "\n",
    "\n",
    "## Pretrained model\n",
    "You can download the pretrained weights from the [link](https://huggingface.co/bert-large-uncased-whole-word-masking/tree/main)\n",
    "You can also download the pretrained weights from the [link](https://huggingface.co/bert-base-uncased)\n",
    "\n",
    "## Special code\n",
    "```python\n",
    "# Using multiprocessing function to deal with large number of examples\n",
    "class SquadDataset(Dataset):\n",
    "    def __init__(self,data_path,vocab_path,max_length=384):\n",
    "        super(SquadDataset,self).__init__()\n",
    "        self.data_path=data_path\n",
    "        self.data_samples=self.get_samples(data_path)\n",
    "        self.tokenizer=BertTokenizer.from_pretrained(vocab_path)\n",
    "        self.max_length=max_length\n",
    "    def get_examples_from_data(self,data):\n",
    "        examples=[]\n",
    "        title=data['title']\n",
    "        for paragraph in data['paragraphs']:\n",
    "            context=paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                qid=qa['id']\n",
    "                question=qa['question']\n",
    "                if \"is_impossible\" in qa:\n",
    "                    is_impossible=qa['is_impossible']\n",
    "                else:\n",
    "                    is_impossible=len(qa['answers'])==0\n",
    "                if is_impossible:\n",
    "                    current_example={'qas_id':qid,'question_text':question,'context_text':context,'is_impossible':is_impossible,'answer_text':''}\n",
    "                    examples.append(current_example)\n",
    "                else:\n",
    "                    current_answer_collectors=[]\n",
    "                    for answer in qa['answers']:\n",
    "                        text=answer['text']\n",
    "                        if text in current_answer_collectors:\n",
    "                            continue\n",
    "                        else:\n",
    "                            current_answer_collectors.append(text)\n",
    "                        answer=answer['answer_start']\n",
    "                        current_example={'qas_id':qid,'question_text':question,'context_text':context,'is_impossible':is_impossible,'answer_text':text}\n",
    "                        examples.append(current_example)\n",
    "        return examples\n",
    "    def get_samples(self,data_path):\n",
    "        with open(data_path,'r',encoding='utf-8') as f:\n",
    "            dataset=json.load(f)\n",
    "            all_data=dataset['data']\n",
    "        processor=multiprocessing.cpu_count()\n",
    "        p=Pool(processor)\n",
    "        result_list=p.map(self.get_examples_from_data,all_data)\n",
    "        all_examples=[]\n",
    "        for examples in result_list:\n",
    "            all_examples+=examples\n",
    "        p.close()\n",
    "        return all_examples\n",
    "# The collate function is used to pad the input sequences to the same length in dataloader\n",
    "def collate_func(batch):\n",
    "    def padding(indices,max_length,pad_idx=0):\n",
    "        pad_indices=[item+[pad_idx]*max(0,max_length-len(item)) for item in indices]\n",
    "        return torch.tensor(pad_indices)\n",
    "    # if padding = 'max_length' is used in tokenizer.encode_plust fuction, then there is no need to pad the sequences to the same size.\n",
    "    result=[(output['input_ids'],output['token_type_ids'],output['attention_mask'],label) for output,label in batch]\n",
    "    input_ids,token_type_ids,attention_mask,labels=zip(*result)\n",
    "    return torch.tensor(input_ids),torch.tensor(token_type_ids),torch.tensor(attention_mask),torch.tensor(labels)\n",
    "\n",
    "    # if padding = 'max_length' is not used in tokenizer.encode_plust fuction, then you should pad the sequences to the same size.\n",
    "    \n",
    "#     result=[(output['input_ids'],output['token_type_ids'],output['attention_mask'],label) for output,label in batch]\n",
    "#     input_ids,token_type_ids,attention_mask,labels=zip(*result)\n",
    "#     labels=torch.tensor(labels)\n",
    "#     max_length=max([len(t) for t in input_ids])\n",
    "    \n",
    "#     input_ids_padded=padding(input_ids,max_length)\n",
    "#     token_type_ids_padded=padding(token_type_ids,max_length)\n",
    "#     attention_mask_padded=padding(attention_mask,max_length)\n",
    "#     return input_ids_padded,token_type_ids_padded,attention_mask_padded,labels\n",
    "\n",
    "# The following code is used to evaluate the fitness of the model.\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def get_tokens(s):\n",
    "  if not s: return []\n",
    "  return normalize_answer(s).split()\n",
    "\n",
    "def compute_exact(a_gold, a_pred):\n",
    "  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "  gold_toks = get_tokens(a_gold)\n",
    "  pred_toks = get_tokens(a_pred)\n",
    "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "  num_same = sum(common.values())\n",
    "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    return int(gold_toks == pred_toks)\n",
    "  if num_same == 0:\n",
    "    return 0\n",
    "  precision = 1.0 * num_same / len(pred_toks)\n",
    "  recall = 1.0 * num_same / len(gold_toks)\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "  return f1\n",
    "\n",
    "# The following function is used to do prediction by customized bert model.\n",
    "def predict_for_single_example(model,tokenizer,question,context,config,verbose=False):\n",
    "    model.eval()\n",
    "    inputs=tokenizer.encode_plus(question, context, max_length=config.max_sequence_len, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    token_ids=inputs['input_ids'].tolist()[0]\n",
    "    \n",
    "    input_ids=inputs['input_ids'].to(config.device)\n",
    "    token_type_ids=inputs['token_type_ids'].to(config.device)\n",
    "    attention_mask=inputs['attention_mask'].to(config.device)\n",
    "    \n",
    "    x=(input_ids,token_type_ids,attention_mask)\n",
    "    initial_hidden_state=torch.zeros(2,input_ids.shape[0],config.gru_hidden_size).to(config.device)\n",
    "    start_logits,end_logits=model(x,initial_hidden_state)\n",
    "    \n",
    "    start_probas,end_probas=torch.softmax(start_logits,dim=-1)[0],torch.softmax(end_logits,dim=-1)[0]\n",
    "            \n",
    "    start_end, score = None, -1\n",
    "    for start, p_start in enumerate(start_probas):\n",
    "        for end, p_end in enumerate(end_probas):\n",
    "            if end >= start and end < start + config.max_a_len:\n",
    "                if p_start * p_end > score:\n",
    "                    start_end = (start, end)\n",
    "                    score = p_start * p_end\n",
    "    start, end = start_end\n",
    "    pred_answer=tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(token_ids[start:end+1],skip_special_tokens=True))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Question:{question}')\n",
    "        print(f'Context:{context}')\n",
    "        if pred_answer=='':\n",
    "            print('There is no answer in the context for this question')\n",
    "        else:\n",
    "            print(f'Answer:{pred_answer}')\n",
    "    return pred_answer\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
